<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  

  
  <title>批量src工具思路 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="一、如何批量刷src？1、w8scan扫描器（模仿bugscan）   python扫描器需要大量的库   这个只需要扫描器自带的库 2、w9scan扫描器（扫描功能增强，目前可以用）   这个扫描器带有1200+种插件，其中其他插件是从www插件中调用的。   这个扫描器爬虫插件很弱，都是内置库，都是基础的爬虫，没有模拟网页、调用js、没有从网页源码中抓取链接的爬虫。   w9scan也不可能获">
<meta property="og:type" content="article">
<meta property="og:title" content="批量src工具思路">
<meta property="og:url" content="http://yoursite.com/2019/09/16/批量src工具思路/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="一、如何批量刷src？1、w8scan扫描器（模仿bugscan）   python扫描器需要大量的库   这个只需要扫描器自带的库 2、w9scan扫描器（扫描功能增强，目前可以用）   这个扫描器带有1200+种插件，其中其他插件是从www插件中调用的。   这个扫描器爬虫插件很弱，都是内置库，都是基础的爬虫，没有模拟网页、调用js、没有从网页源码中抓取链接的爬虫。   w9scan也不可能获">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-09-16T10:53:01.792Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="批量src工具思路">
<meta name="twitter:description" content="一、如何批量刷src？1、w8scan扫描器（模仿bugscan）   python扫描器需要大量的库   这个只需要扫描器自带的库 2、w9scan扫描器（扫描功能增强，目前可以用）   这个扫描器带有1200+种插件，其中其他插件是从www插件中调用的。   这个扫描器爬虫插件很弱，都是内置库，都是基础的爬虫，没有模拟网页、调用js、没有从网页源码中抓取链接的爬虫。   w9scan也不可能获">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-批量src工具思路" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/09/16/批量src工具思路/" class="article-date">
  <time datetime="2019-09-16T05:03:00.000Z" itemprop="datePublished">2019-09-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      批量src工具思路
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="一、如何批量刷src？"><a href="#一、如何批量刷src？" class="headerlink" title="一、如何批量刷src？"></a>一、如何批量刷src？</h3><h4 id="1、w8scan扫描器（模仿bugscan）"><a href="#1、w8scan扫描器（模仿bugscan）" class="headerlink" title="1、w8scan扫描器（模仿bugscan）"></a>1、w8scan扫描器（模仿bugscan）<br></h4><p>   python扫描器需要大量的库<br><br>   这个只需要扫描器自带的库<br></p>
<h4 id="2、w9scan扫描器（扫描功能增强，目前可以用）"><a href="#2、w9scan扫描器（扫描功能增强，目前可以用）" class="headerlink" title="2、w9scan扫描器（扫描功能增强，目前可以用）"></a>2、w9scan扫描器（扫描功能增强，目前可以用）<br></h4><p>   这个扫描器带有1200+种插件，其中其他插件是从www插件中调用的。<br><br>   这个扫描器爬虫插件很弱，都是内置库，都是基础的爬虫，没有模拟网页、调用js、没有从网页源码中抓取链接的爬虫。<br><br>   w9scan也不可能获取太多了url做以分析。<br><br>   w9scan的插件库一直在丰富。慢慢地w9scan慢慢变成了信息收集地工具。<br><br>   现在的话，可以使用第三方的库，使用docker就ok！<br></p>
<h4 id="3、w10scan扫描器（批量扫描漏洞，全自动扫描）"><a href="#3、w10scan扫描器（批量扫描漏洞，全自动扫描）" class="headerlink" title="3、w10scan扫描器（批量扫描漏洞，全自动扫描）"></a>3、w10scan扫描器（批量扫描漏洞，全自动扫描）<br></h4><p>   信息收集批量的更加好。<br><br>   目前只处于想法阶段<br><br>   w10scan目标喂大量url<br><br>   github链接地址:<a href="https://github.com/boy-hack/w10scan" target="_blank" rel="noopener">https://github.com/boy-hack/w10scan</a><br><br>   w10scan扫描一些通用的漏洞-&gt;自动扫漏洞来挖src。<br><br>   开发原理：批量扫漏洞，网络并发，漏洞插件的编写。<br><br>   可以把漏洞报告上传到网页上，优化字典传到网页上，然后下发。<br></p>
<h4 id="4、w11scan扫描器（解决w10的向量问题，分布式指纹识别）"><a href="#4、w11scan扫描器（解决w10的向量问题，分布式指纹识别）" class="headerlink" title="4、w11scan扫描器（解决w10的向量问题，分布式指纹识别）"></a>4、w11scan扫描器（解决w10的向量问题，分布式指纹识别）<br></h4><p>   通过一些路径判断指纹(cms)，但是指纹一多，效率会变低。<br><br>   深度学习来识别指纹，效果也不太好。<br><br>   三种识别方式：关键字、正则、md5。<br><br>   操作：新增任务，粘贴url。<br></p>
<h2 id="二、如何将渗透经验转化为工具？？"><a href="#二、如何将渗透经验转化为工具？？" class="headerlink" title="二、如何将渗透经验转化为工具？？"></a>二、如何将渗透经验转化为工具？？</h2><h4 id="1、学习渗透总结"><a href="#1、学习渗透总结" class="headerlink" title="1、学习渗透总结"></a>1、学习渗透总结</h4><p>   学习渗透时，很多地方都是通过参数污染来达到目的。<br><br>   但是一个网站链接那么多，想把它们全部污染的话，效率问题会很低下。<br><br>   所以想起造个轮子，但是脚本小子驾车去远方，怎么就把时间花到造轮子上呢？<br><br>   渗透基础只是我都懂，但是真正渗透一个网站时不知道怎么办？–&gt;用一款工具来帮助完成<br></p>
<h4 id="2、手工测试太机械、太累了，如何将这些自动化？"><a href="#2、手工测试太机械、太累了，如何将这些自动化？" class="headerlink" title="2、手工测试太机械、太累了，如何将这些自动化？"></a>2、手工测试太机械、太累了，如何将这些自动化？</h4><p>   常见漏洞：<br><br>   1.信息泄露<br><br>   2.错误配置<br><br>   3.前端漏洞<br><br>   4.逻辑漏洞<br><br>   5.弱口令<br><br>   6.web注入漏洞<br><br>   7.文件包含<br><br>   其中大部分类型都可以找到代码利用，利用无外乎是发送payload，然后判断返回包是怎样，用各种算法判断它是否存在。<br></p>
<h4 id="3、传统扫描器流程"><a href="#3、传统扫描器流程" class="headerlink" title="3、传统扫描器流程"></a>3、传统扫描器流程</h4><p>   1.爬虫<br><br>   2.得到url<br><br>   3.特定的漏洞payload验证<br><br>   4.验证成功-&gt;报告；验证失败-&gt;下一个<br><br>   类似awvs、appscan已经做得足够好了，但是扫描地非常慢。但是慢也有慢地道理，它们会利用它们的规则进行检查。<br><br>   所以这么想，在传统的扫描器上，我们不需要造轮子。因为传统扫描器做得非常好了。<br><br>   兴趣很好去模仿！但如果自己去造一个跟awvs一样的，这也不现实。<br><br>   传统扫描器做的太成熟，我们需要打破常规，根据我们的渗透经验去编写。<br><br>   <br><br>   渗透经验：抽象成编程算法，构成各种各样的规则。<br></p>
<h4 id="4、规则？"><a href="#4、规则？" class="headerlink" title="4、规则？"></a>4、规则？</h4><h6 id="猪猪侠乌云大牛找到的很多漏洞都是以一个基础组件作为入口。然后以此来深挖的。"><a href="#猪猪侠乌云大牛找到的很多漏洞都是以一个基础组件作为入口。然后以此来深挖的。" class="headerlink" title="猪猪侠乌云大牛找到的很多漏洞都是以一个基础组件作为入口。然后以此来深挖的。"></a>猪猪侠乌云大牛找到的很多漏洞都是以一个基础组件作为入口。然后以此来深挖的。<br></h6><p>   基础组件漏洞：Struts2、weblogic（有现成的poc，即规则对它进行验证的）<br></p>
<h6 id="猜想？"><a href="#猜想？" class="headerlink" title="猜想？"></a>猜想？<br></h6><p>   猪猪侠大牛是不是有一个强大的扫描器，把它漏洞中所有漏洞类型还有字典做为了规则，发现都是网上公开或者没有公开的常用漏洞规则。<br><br>   它们组合起来威力还是巨大的。<br></p>
<h6 id="猪猪侠大牛描述自动化扫描器（now！脚本套脚本，一键完成）"><a href="#猪猪侠大牛描述自动化扫描器（now！脚本套脚本，一键完成）" class="headerlink" title="猪猪侠大牛描述自动化扫描器（now！脚本套脚本，一键完成）"></a>猪猪侠大牛描述自动化扫描器（now！脚本套脚本，一键完成）</h6><p>   · 模块化高可扩展（脚本Python）–&gt;在漏洞爆发时可以迅速入库。<br><br>   · 系统、服务、组件指纹标准化入库–&gt;迅速调用相关组件攻击<br><br>   · 高覆盖率（分布式全球节点）–&gt;提高效率<br><br>   · 重新定义网络边界（Socks5代理、隧道）–&gt;提高效率<br></p>
<h4 id="5、Github信息泄露工具（抓住关键词）"><a href="#5、Github信息泄露工具（抓住关键词）" class="headerlink" title="5、Github信息泄露工具（抓住关键词）"></a>5、Github信息泄露工具（抓住关键词）</h4><p>   挖src的话，可以一直监控这几个src的关键词，当发现敏感的信息泄露时，程序会邮件给你。<br></p>
<h4 id="6、监控知名组件更新记录"><a href="#6、监控知名组件更新记录" class="headerlink" title="6、监控知名组件更新记录"></a>6、监控知名组件更新记录</h4><p>   链接：<a href="https://github.com/knownsec/wam" target="_blank" rel="noopener">https://github.com/knownsec/wam</a><br><br>   第一时间获得知名程序的跟新信息，如果是一个漏洞跟新的话，那么会第一时间获得详情。<br><br>   知名厂商更新了，我们可以第一时间获得知名厂商的更新代码，来判断它是否修复了漏洞，如果它修复了某个漏洞的话，那么可以知道它之前有哪些项目。<br></p>
<h4 id="7、更多的规则？"><a href="#7、更多的规则？" class="headerlink" title="7、更多的规则？"></a>7、更多的规则？</h4><h6 id="猪猪侠大牛的很多字典也与BBScan的字典相似，不错的字典，出其不意。"><a href="#猪猪侠大牛的很多字典也与BBScan的字典相似，不错的字典，出其不意。" class="headerlink" title="猪猪侠大牛的很多字典也与BBScan的字典相似，不错的字典，出其不意。"></a>猪猪侠大牛的很多字典也与BBScan的字典相似，不错的字典，出其不意。</h6><p>   链接：<a href="https://github.com/lijiejie/BBScan" target="_blank" rel="noopener">https://github.com/lijiejie/BBScan</a><br><br>   爬虫分析链接，利用特定的payload、poc去访问。<br><br>   安全从业者自研开源扫描器合辑：<br><br>   链接：<a href="https://github.com/We5ter/Scanners-Box" target="_blank" rel="noopener">https://github.com/We5ter/Scanners-Box</a><br></p>
<h4 id="8、自建网络资产引擎？"><a href="#8、自建网络资产引擎？" class="headerlink" title="8、自建网络资产引擎？"></a>8、自建网络资产引擎？</h4><p>   链接：<a href="https://github.com/0xbug/Biu" target="_blank" rel="noopener">https://github.com/0xbug/Biu</a><br></p>
<h2 id="三、打造自己的兵器（如何批量化地扫描漏洞）"><a href="#三、打造自己的兵器（如何批量化地扫描漏洞）" class="headerlink" title="三、打造自己的兵器（如何批量化地扫描漏洞）"></a>三、打造自己的兵器（如何批量化地扫描漏洞）</h2><h4 id="1、全自动刷Src"><a href="#1、全自动刷Src" class="headerlink" title="1、全自动刷Src"></a>1、全自动刷Src</h4><h6 id="第一步（突破口，为了获得更大的权限）"><a href="#第一步（突破口，为了获得更大的权限）" class="headerlink" title="第一步（突破口，为了获得更大的权限）"></a>第一步（突破口，为了获得更大的权限）</h6><p>   利用想法：针对url进行探测↓（常见探测点）<br><br>   · 基础组件漏洞<br><br>   · 常见漏洞类型<br><br>   · 端口弱口令及未授权<br><br>   链接：<a href="http://www.freebuf.cmo/sectool/176562.html" target="_blank" rel="noopener">http://www.freebuf.cmo/sectool/176562.html</a><br><br>   全自动，还可以写自动提交到Src的代码。<br></p>
<h4 id="2、出征前的准备"><a href="#2、出征前的准备" class="headerlink" title="2、出征前的准备"></a>2、出征前的准备</h4><h6 id="1-扫描器架构：插件化、有插件的调用方式、优秀的网络并发。（POC-T、Pocsuite、Osprey-鱼鹰-）"><a href="#1-扫描器架构：插件化、有插件的调用方式、优秀的网络并发。（POC-T、Pocsuite、Osprey-鱼鹰-）" class="headerlink" title="1.扫描器架构：插件化、有插件的调用方式、优秀的网络并发。（POC-T、Pocsuite、Osprey[鱼鹰]）"></a>1.扫描器架构：插件化、有插件的调用方式、优秀的网络并发。（POC-T、Pocsuite、Osprey[鱼鹰]）</h6><p>   其中POC-T比较简单，使用方便。<br><br>   写插件的话，需要定义很多东西。<br></p>
<h6 id="2-用什么扫描规则？：插件脚本总结，常用漏洞脚本整理、猪猪侠乌云漏洞字典、规则整理"><a href="#2-用什么扫描规则？：插件脚本总结，常用漏洞脚本整理、猪猪侠乌云漏洞字典、规则整理" class="headerlink" title="2.用什么扫描规则？：插件脚本总结，常用漏洞脚本整理、猪猪侠乌云漏洞字典、规则整理"></a>2.用什么扫描规则？：插件脚本总结，常用漏洞脚本整理、猪猪侠乌云漏洞字典、规则整理</h6><h4 id="3、自动化刷Src雏形"><a href="#3、自动化刷Src雏形" class="headerlink" title="3、自动化刷Src雏形"></a>3、自动化刷Src雏形</h4><p>   改造过的POC-T插件框架：<br><br>   链接：<a href="https://github.com/boy-hak/poc-t" target="_blank" rel="noopener">https://github.com/boy-hak/poc-t</a><br><br>   因为：POC-T不能使用多个url，通过多个插件来扫，改造支持！<br><br>   POC-T插件操作：<br><br>   1.进入文件夹下ls<br><br>   2.查看下目标文件cat target.txt<br><br>   3.查找子域名<br><br>   python POC-T.py -t 20 -s findsub -iF target.txt<br><br>   查找子域名都是调用一些接口。-&gt;效率<br><br>   4.扫描完后会在output文件夹下生成一个txt文件。<br><br>   5.结果复制到POC-T的根目录下，命名为sub.txt，然后对其进行过滤。<br><br>   6.过滤出有waf的、不能访问的，全部过滤掉,增加效率。<br><br>   python POC-T.py -t 20 -s waf -iF sub.txt<br><br>   7.过滤后还是在output文件下，复制到POC-T的根目录下，命名为waf.txt（waf扫描过滤出来的）<br><br>   8.对过滤出来的url进行想法验证<br><br>   原来这个–batch原框架是没有的，增加fuzz模式特意写的命令参数。<br><br>   python POC-T.py -t 40 –batch -iF waf.txt<br><br>   这个可能会跑很久,挂着！<br></p>
<p>   9.可以看到加载了多个插件，每个插件对应一个url。Total：xxx<br><br>   10.新开一个窗口，对waf.txt里面的url进行一次爬虫。<br><br>   python POC-T.py -t 20 -s craw -iF waf.txt<br><br>   这个插件会爬出很多结果。<br><br>   11.在output文件夹下，复制到POC-T的根目录下，命名为craw.txt。<br><br>   然后可以对其进行sql注入的检测了。<br><br>   python POC-T.py -t 20 -s vulscan -iF craw.txt<br><br>   12.重复步骤，探测爬虫的XSS注入。<br><br>   python POC-T.py -t 20 -s xss -iF craw.txt<br><br>   <br><br>   13.想添加fuzz脚本就添加到fuzz目录中。<br></p>
<p>   所有文档都可以在output中看到。<br></p>
<p>• poc-t.py -eT -t 20 -s findsub -iF target.txt 查找子域名<br><br>• poc-t.py -eT -t 20 -s waf -iF target.txt 使用waf插件过滤域名<br><br>• poc-t.py -eT -t 20 —batch -iF target.txt 使用fuzz插件扫描<br><br>• poc-t.py -eT -t 20 -s craw -iF target.txt 使用爬虫探测<br><br>• poc-t.py -eT -t 20 -s vulscan -iF craw.txt 探测爬虫的SQL注入<br><br>• poc-t.py -eT -t 20 -s xss -iF craw.txt 探测爬虫的XSS注入<br></p>
<h6 id="因此可以参考POC-T，写一个全自动的工具。"><a href="#因此可以参考POC-T，写一个全自动的工具。" class="headerlink" title="因此可以参考POC-T，写一个全自动的工具。"></a>因此可以参考POC-T，写一个全自动的工具。</h6><h4 id="4、全自动端口探测"><a href="#4、全自动端口探测" class="headerlink" title="4、全自动端口探测"></a>4、全自动端口探测</h4><p>   • 获得SRC所属域名的IP段/ip列表（即waf.txt）<br><br>   • IP段转换工具 W8fuckcdn (<a href="https://github.com/boy-" target="_blank" rel="noopener">https://github.com/boy-</a> hack/w8fuckcdn)<br><br>   这是一款自动化扫描全网，绕过cnd的一种程序。<br><br>   • get_ips.py -f target.txt –ips<br><br>   W8fuckcdn中有get_ips.py可以获取指定的ip段。<br><br>   • masscan + F-Scrack结合版（F-Scrack是端口扫描爆破的）<br></p>
<h6 id="使用方法："><a href="#使用方法：" class="headerlink" title="使用方法："></a>使用方法：</h6><p>   1.在W8fuckcdn打开终端<br><br>   2.python get_ips.py -f waf.txt –ips<br><br>   3.将那些ip自动生成ip段<br><br>   4.生成存储IP段文件output.txt<br><br>   5.扫描这些IP段，扫描ip段。先将ip段复制到masscan中target.log中去<br><br>   在当前目录打开终端，执行：<br><br>   sudo python masscan.py<br><br>   6.首先进行masscan扫描<br><br>   7.然后就会自动爆破一些端口（数据库）弱口令之类的<br></p>
<h6 id="猜想：将前面POC-T全部自动化，再把扫描ip段自动化，结果全部传到数据库中存储，前面再用一个web端进行展示，那么就是资源搜集，危险情报之类的。"><a href="#猜想：将前面POC-T全部自动化，再把扫描ip段自动化，结果全部传到数据库中存储，前面再用一个web端进行展示，那么就是资源搜集，危险情报之类的。" class="headerlink" title="猜想：将前面POC-T全部自动化，再把扫描ip段自动化，结果全部传到数据库中存储，前面再用一个web端进行展示，那么就是资源搜集，危险情报之类的。"></a>猜想：将前面POC-T全部自动化，再把扫描ip段自动化，结果全部传到数据库中存储，前面再用一个web端进行展示，那么就是资源搜集，危险情报之类的。</h6><h6 id="进一步猜想：数据存储起来，然后用接口调用，进行二次判断之类的。"><a href="#进一步猜想：数据存储起来，然后用接口调用，进行二次判断之类的。" class="headerlink" title="进一步猜想：数据存储起来，然后用接口调用，进行二次判断之类的。"></a>进一步猜想：数据存储起来，然后用接口调用，进行二次判断之类的。</h6><h2 id="四、打造自己的渗透生态链（seebug-pocsuite-zoomeye？）"><a href="#四、打造自己的渗透生态链（seebug-pocsuite-zoomeye？）" class="headerlink" title="四、打造自己的渗透生态链（seebug+pocsuite+zoomeye？）"></a>四、打造自己的渗透生态链（seebug+pocsuite+zoomeye？）</h2><h4 id="1、seebug-pocsuite-zoomeye"><a href="#1、seebug-pocsuite-zoomeye" class="headerlink" title="1、seebug+pocsuite+zoomeye"></a>1、seebug+pocsuite+zoomeye</h4><p>   创宇的产品。dddd<br></p>
<h6 id="假如zoomeye提供一个url；再通过seebug提供一个插件；最后通过这个pocsuite获取这个插件，再获取zoomeye的url进行扫描，其实就是可以构成一个渗透生态链。"><a href="#假如zoomeye提供一个url；再通过seebug提供一个插件；最后通过这个pocsuite获取这个插件，再获取zoomeye的url进行扫描，其实就是可以构成一个渗透生态链。" class="headerlink" title="假如zoomeye提供一个url；再通过seebug提供一个插件；最后通过这个pocsuite获取这个插件，再获取zoomeye的url进行扫描，其实就是可以构成一个渗透生态链。"></a>假如zoomeye提供一个url；再通过seebug提供一个插件；最后通过这个pocsuite获取这个插件，再获取zoomeye的url进行扫描，其实就是可以构成一个渗透生态链。</h6><p>   什么都不用做，只需要维护这三个系统将其自动化，那么则构成一个完整的生态链。<br><br>   插件库、指纹库的收集。<br><br>   入库环节比较重要，即资产梳理。<br></p>
<h4 id="1、统一的HTTP库？"><a href="#1、统一的HTTP库？" class="headerlink" title="1、统一的HTTP库？"></a>1、统一的HTTP库？</h4><p>   • Hack-requests 为黑客打造的HTTP库<br>   • 在编写poc时候，poc模块最好是request<br>   • <a href="https://github.com/boy-hack/hack-reques" target="_blank" rel="noopener">https://github.com/boy-hack/hack-reques</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/09/16/批量src工具思路/" data-id="ck0majmju0002dgv3690vj0g2" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2019/09/13/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/09/">September 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/09/16/批量src工具思路/">批量src工具思路</a>
          </li>
        
          <li>
            <a href="/2019/09/13/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/09/12/爱你素素-1/">爱你素素</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>